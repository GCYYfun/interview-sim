from menglong import Model
from menglong.agents.role_play import RoleAgent
from menglong.ml_model.schema.ml_request import (
    SystemMessage as system,
    UserMessage as user,
    AssistantMessage as assistant,
    ToolMessage as tool,
)
import yaml
import json
import os
import glob
from datetime import datetime
from pathlib import Path
import traceback

from menglong.utils.log import configure, get_logger
from menglong.utils.log import print_json, print_message

from interview_assistant import InterviewAssistant
from eval_assistant import EvalAssistant
import pandas as pd


# æ—¶é—´
configure(log_file=f"agent_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")


def test():
    print_message("Hello from interview-sim!")
    model = Model(model_id="us.anthropic.claude-sonnet-4-20250514-v1:0")
    res = model.chat([user(content="ä½ å¥½")])
    print_message(res)


class InterviewContextManager:
    def __init__(self):
        """åˆå§‹åŒ–é¢è¯•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        # ---
        self.interviewer_context = []  # model chat context for interviewer
        self.candidate_context = []  # model chat context for candidate
        self.hr_context = []  # model chat context for hr
        # ---
        # å¯¹è¯å†å²
        self.conversation_history = []  # å¯¹è¯å†å²è®°å½•
        self.hr_evaluations = []  # HRè¯„ä¼°è®°å½•,è¯„ä¼°æ¯ä¸€æ¬¡å¯¹è¯
        self.result_summary = []  # è®°å½•å…³é”®æœ‰æ•ˆæ»¡è¶³hréœ€æ±‚çš„é—®ç­”
        self.current_round = 0  # å½“å‰å¯¹è¯è½®æ¬¡
        self.interview_topic = None  # é¢è¯•ä¸»é¢˜
        self.cache_context = None

    def add_message(self, role_name, content):
        """æ·»åŠ å¯¹è¯æ¶ˆæ¯"""
        message = {
            "role": role_name,
            "content": content,
            "round": self.current_round,
        }
        self.conversation_history.append(message)

    def add_hr_evaluation(self, evaluation):
        """æ·»åŠ HRè¯„ä¼°"""
        self.hr_evaluations.append(evaluation)

    def get_conversation_context(self):
        """è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡"""
        return self.conversation_history

    def get_hr_evaluations(self):
        """è·å–HRè¯„ä¼°è®°å½•"""
        return self.hr_evaluations

    def get_result_summary(self):
        """è·å–å…³é”®æœ‰æ•ˆé—®ç­”æ€»ç»“"""
        return self.result_summary


class InterviewerAgent(RoleAgent):
    def __init__(self, role_info):
        super().__init__(role_config=role_info)


class CandidateAgent(RoleAgent):
    def __init__(self, role_info):
        super().__init__(role_config=role_info)


class RealDataCandidateAgent:
    """åŸºäºçœŸå®ç®€å†æ•°æ®çš„å€™é€‰äººAgent"""

    def __init__(self, candidate_data):
        """
        åˆå§‹åŒ–çœŸå®æ•°æ®å€™é€‰äººAgent

        Args:
            candidate_data: åŒ…å«ç®€å†ã€JDã€å²—ä½ä¿¡æ¯ç­‰çš„å­—å…¸
        """
        self.candidate_data = candidate_data
        self.resume = candidate_data.get("resume", "")
        self.jd = candidate_data.get("jd", "")
        self.position = candidate_data.get("position", "")
        self.intelligence_requirement = candidate_data.get(
            "intelligence_requirement", 0
        )
        self.model = Model()

        # æ„å»ºå€™é€‰äººäººè®¾æç¤º
        self.persona_prompt = self._build_persona_prompt()

    def _build_persona_prompt(self):
        """æ„å»ºå€™é€‰äººäººè®¾æç¤º"""
        return f"""
ä½ æ˜¯ä¸€ä½æ±‚èŒè€…ï¼Œæ­£åœ¨å‚åŠ {self.position}å²—ä½çš„é¢è¯•ã€‚

ä½ çš„ç®€å†èƒŒæ™¯ï¼š
{self.resume}

åº”è˜çš„å²—ä½è¦æ±‚ï¼š
{self.jd}

å²—ä½å¯¹èªæ˜åº¦çš„è¦æ±‚ï¼š{self.intelligence_requirement}/10

è¯·æ ¹æ®ä½ çš„ç®€å†èƒŒæ™¯ï¼Œä»¥ç¬¬ä¸€äººç§°å›ç­”é¢è¯•å®˜çš„é—®é¢˜ã€‚è¦æ±‚ï¼š
1. å›ç­”è¦ç¬¦åˆç®€å†ä¸­çš„ç»å†å’ŒèƒŒæ™¯
2. ä½“ç°å‡ºé€‚åˆè¯¥å²—ä½çš„èƒ½åŠ›å’Œç‰¹è´¨
3. å›ç­”è¦çœŸå®å¯ä¿¡ï¼Œä¸è¦å¤¸å¤§
4. è¯­æ°”è¦è‡ªç„¶ã€è¯šæ³ï¼Œä½“ç°æ±‚èŒè€…çš„è°¨æ…å’Œç§¯æ
5. å¦‚æœé—®é¢˜æ¶‰åŠç®€å†ä¸­æ²¡æœ‰çš„ç»å†ï¼Œè¦è¯šå®è¯´æ˜å¹¶å±•ç¤ºå­¦ä¹ æ„æ„¿
6. å›ç­”é•¿åº¦é€‚ä¸­ï¼Œæ—¢è¦è¯¦ç»†åˆä¸è¦è¿‡äºå†—é•¿

ç°åœ¨è¯·å‡†å¤‡å›ç­”é¢è¯•å®˜çš„é—®é¢˜ã€‚
"""

    def answer_question(self, question):
        """
        æ ¹æ®ç®€å†èƒŒæ™¯å›ç­”é¢è¯•é—®é¢˜

        Args:
            question: é¢è¯•å®˜çš„é—®é¢˜

        Returns:
            str: å€™é€‰äººçš„å›ç­”
        """
        try:
            # æ„å»ºå®Œæ•´çš„å¯¹è¯æç¤º
            full_prompt = f"""
{self.persona_prompt}

é¢è¯•å®˜é—®ï¼š{question}

è¯·ä»¥å€™é€‰äººèº«ä»½å›ç­”è¿™ä¸ªé—®é¢˜ï¼š
"""

            response = self.model.chat([user(content=full_prompt)])
            answer = response.text  # self._extract_response_text(response)

            # æ¸…ç†æ ¼å¼ï¼Œç¡®ä¿å›ç­”è‡ªç„¶
            answer = self._clean_answer(answer)

            return answer

        except Exception as e:
            return f"æŠ±æ­‰ï¼Œæˆ‘éœ€è¦ä¸€ç‚¹æ—¶é—´æ€è€ƒè¿™ä¸ªé—®é¢˜ã€‚èƒ½å¦è¯·æ‚¨å†è¯¦ç»†è¯´æ˜ä¸€ä¸‹ï¼Ÿ"

    def _extract_response_text(self, response):
        """æå–å“åº”æ–‡æœ¬"""
        if hasattr(response, "content"):
            return response.content
        elif isinstance(response, dict) and "content" in response:
            return response["content"]
        elif isinstance(response, str):
            return response
        else:
            return str(response)

    def _clean_answer(self, answer):
        """æ¸…ç†å›ç­”æ ¼å¼"""
        # ç§»é™¤å¯èƒ½çš„è§’è‰²æ ‡è¯†
        if answer.startswith(("å€™é€‰äººï¼š", "æ±‚èŒè€…ï¼š", "æˆ‘ï¼š")):
            answer = answer.split("ï¼š", 1)[1].strip()
        elif answer.startswith(("å€™é€‰äºº:", "æ±‚èŒè€…:", "æˆ‘:")):
            answer = answer.split(":", 1)[1].strip()

        # ç§»é™¤å¤šä½™çš„å¼•å·
        answer = answer.strip("\"'")

        return answer.strip()

    def get_candidate_info_summary(self):
        """è·å–å€™é€‰äººä¿¡æ¯æ‘˜è¦"""
        return {
            "position": self.position,
            "intelligence_requirement": self.intelligence_requirement,
            "resume_preview": (
                self.resume[:200] + "..." if len(self.resume) > 200 else self.resume
            ),
            "jd_preview": self.jd[:200] + "..." if len(self.jd) > 200 else self.jd,
        }


class HRAgent(RoleAgent):
    def __init__(self, role_info):
        super().__init__(role_config=role_info)

    def opening_statement(self, topic=None):
        """HRå¼€åœºç™½"""
        if topic:
            return f"[HR]:æ¬¢è¿å‚åŠ æˆ‘ä»¬å…¬å¸çš„é¢è¯•ï¼ä»Šå¤©æˆ‘ä»¬ä¼šé€šè¿‡æé—®äº¤æµçš„æ–¹å¼æ¥äº†è§£æ‚¨çš„èƒŒæ™¯å’Œèƒ½åŠ›ï¼Œå°¤å…¶å¯¹{topic}å²—ä½çš„é€‚é…æƒ…å†µã€‚æ¥ä¸‹æ¥äº¤ç”±æˆ‘ä»¬çš„å²—ä½é¢è¯•å®˜ä¸æ‚¨äº¤æµã€‚è¯·æ”¾è½»æ¾ï¼Œå±•ç¤ºæ‚¨æœ€å¥½çš„ä¸€é¢ã€‚"
        return "[HR]:æ¬¢è¿å‚åŠ æˆ‘ä»¬å…¬å¸çš„é¢è¯•ï¼ä»Šå¤©æˆ‘ä»¬ä¼šé€šè¿‡ä¸€äº›é—®é¢˜æ¥äº†è§£æ‚¨çš„èƒŒæ™¯å’Œèƒ½åŠ›ã€‚æ¥ä¸‹æ¥äº¤ç”±æˆ‘ä»¬çš„å²—ä½é¢è¯•å®˜ä¸æ‚¨äº¤æµã€‚è¯·æ”¾è½»æ¾ï¼Œå±•ç¤ºæ‚¨æœ€å¥½çš„ä¸€é¢ã€‚"

    def evaluate_response(self, question, answer):
        """è¯„ä¼°å€™é€‰äººå›ç­”"""

        prompt = f"é¢è¯•å®˜çš„é—®é¢˜ : {question}\n\nå€™é€‰äººçš„å›ç­” : {answer}\n\nè¯·æ ¹æ®é—®é¢˜å’Œå›ç­”å¯¹å€™é€‰äººè¿›è¡Œè¯„ä¼°æ˜¯å¦ç¬¦åˆå†°å±±æ¨¡å‹ä¸­çš„è¦æ±‚,å¦‚æœç¬¦åˆè¦æ±‚ï¼Œè®°å½•é—®é¢˜å’Œå…³é”®å›ç­”å’Œè¯„ä¼°ç»“æœï¼Œå¹¶è¾“å‡º[OK]"

        res = self.chat(prompt)

        return res

    def should_end_interview(self, conversation_history):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸé¢è¯•"""
        # ç®€å•çš„ç»“æŸæ¡ä»¶ï¼šè¶…è¿‡3è½®å¯¹è¯
        dialogue_count = len(
            [
                msg
                for msg in conversation_history
                if msg["role"] in ["å²—ä½é¢è¯•å®˜", "å€™é€‰äºº"]
            ]
        )
        return dialogue_count >= 6  # 3è½®é—®ç­”

    def evaluate_candidate(self, candidate):
        """æœ€ç»ˆè¯„ä¼°å€™é€‰äºº"""
        evaluations = self.collected_info.get("evaluations", [])
        if not evaluations:
            return "éœ€è¦æ›´å¤šä¿¡æ¯è¿›è¡Œè¯„ä¼°"

        avg_score = sum(eval_item["score"] for eval_item in evaluations) / len(
            evaluations
        )
        if avg_score >= 4:
            return "æ¨èå½•ç”¨"
        elif avg_score >= 3:
            return "å¯ä»¥è€ƒè™‘"
        else:
            return "ä¸æ¨è"


class InterviewConversation:
    """Interview conversation"""

    def __init__(
        self, interviewer: InterviewerAgent, candidate: CandidateAgent, hr: HRAgent
    ):
        self.interviewer = interviewer
        self.candidate = candidate
        self.hr = hr
        self.context_manager = InterviewContextManager()
        self.max_rounds = 5  # æœ€å¤§è½®æ¬¡

    def chat(self, topic=None):
        """ä¸‰äººé¢è¯•å¯¹è¯æµç¨‹"""
        if topic:
            self.context_manager.interview_topic = topic

        print_message("=== é¢è¯•å¼€å§‹ ===")

        # HRå¼€åœºç™½
        hr_opening = self.hr.opening_statement(topic)
        print_message(f"{hr_opening}", title=self.hr.id, use_panel=True)
        self.context_manager.add_message(self.hr.id, hr_opening)

        for round_num in range(1, self.max_rounds + 1):
            self.context_manager.current_round = round_num
            print_message(f"\n--- ç¬¬ {round_num} è½®å¯¹è¯ ---")

            # 1. é¢è¯•å®˜æé—®
            if round_num == 1:
                # ç¬¬ä¸€è½®ï¼Œé¢è¯•å®˜ä¸»åŠ¨æé—®
                # self.context_manager.interviewer_context.append(
                #     user(content=hr_opening)
                # )
                interviewer_question = self.interviewer.chat(hr_opening)
                # self.context_manager.interviewer_context.append(
                #     assistant(content=interviewer_question)
                # )
                print_message(
                    f"{interviewer_question}", title=self.interviewer.id, use_panel=True
                )
            else:
                # åç»­è½®æ¬¡ï¼ŒåŸºäºä¹‹å‰çš„å¯¹è¯ç»§ç»­æé—®
                if self.context_manager.cache_context is not None:
                    interviewer_question = self.interviewer.chat(
                        self.context_manager.cache_context
                    )
                    print_message(
                        f"{interviewer_question}",
                        title=self.interviewer.id,
                        use_panel=True,
                    )
                    self.context_manager.cache_context = None
                else:
                    raise ValueError("å€™é€‰äººå›ç­”å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹, ä¸”é•¿åº¦å¤§äº1")

            self.context_manager.add_message(self.interviewer.id, interviewer_question)

            # 2. å€™é€‰äººå›ç­”
            # self.context_manager.candidate_context.append(
            #     user(content=interviewer_question)
            # )
            candidate_answer = self.candidate.chat(interviewer_question)
            # self.context_manager.candidate_context.append(
            #     assistant(content=candidate_answer)
            # )
            print_message(
                f"{candidate_answer}",
                title=self.candidate.id,
                use_panel=True,
            )
            self.context_manager.cache_context = candidate_answer
            self.context_manager.add_message(self.candidate.id, candidate_answer)

            # 3. HRè¯„ä¼°
            hr_evaluation = self.hr.evaluate_response(
                interviewer_question, candidate_answer
            )
            if "[OK]" in hr_evaluation:
                self.context_manager.result_summary.append(hr_evaluation)
            print_message(f"{hr_evaluation}", title=self.hr.id, use_panel=True)
            self.context_manager.add_hr_evaluation(hr_evaluation)

            # æ£€æŸ¥æ˜¯å¦ç»“æŸé¢è¯•
            if self.hr.should_end_interview(
                self.context_manager.get_conversation_context()
            ):
                print_message(f"\n{self.hr.id}: é¢è¯•ç»“æŸï¼Œæ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼")
                break

        print_message("\n=== é¢è¯•ç»“æŸ ===")
        return self.context_manager.get_conversation_context()


def interview_scene():
    """æ¨¡æ‹Ÿé¢è¯•æµç¨‹"""
    print_message("ğŸ“‹ é¢è¯•æ¨¡æ‹ŸåŠŸèƒ½")
    print_message("è¯·é€‰æ‹©é¢è¯•æ¨¡å¼:")

    try:
        mode_choice = input(
            """
1. æ ‡å‡†æ¨¡æ‹Ÿé¢è¯• (ä¸‰æ–¹è§’è‰²æ‰®æ¼”)
2. çœŸå®æ•°æ®é¢è¯• (å€™é€‰äººä½¿ç”¨çœŸå®ç®€å†ä¸HRåŠ©æ‰‹å¯¹è¯)
3. è¿”å›ä¸»èœå•

è¯·è¾“å…¥é€‰æ‹© (1-3): """
        )

        if mode_choice == "1":
            standard_interview_simulation()
        elif mode_choice == "2":
            real_data_interview_simulation()
        elif mode_choice == "3":
            return
        else:
            print_message("æ— æ•ˆé€‰æ‹©")

    except Exception as e:
        print_message(f"âŒ é¢è¯•æ¨¡æ‹Ÿå¤±è´¥: {e}")
        print_message(traceback.format_exc())


def standard_interview_simulation():
    """æ ‡å‡†ä¸‰æ–¹è§’è‰²æ‰®æ¼”é¢è¯•æ¨¡æ‹Ÿ"""
    # è¯»å– prompts ç›®å½• ä¸‹çš„ yamlé…ç½®æ–‡ä»¶
    dir_path = Path("prompts")
    role_infos = {}

    # æ£€æŸ¥promptsç›®å½•æ˜¯å¦å­˜åœ¨
    if dir_path.exists():
        files = [f.name for f in dir_path.iterdir() if f.is_file()]
        print(f"æ–‡ä»¶åˆ—è¡¨: {files}")
        for file in files:
            if file.endswith(".yaml"):
                file_path = dir_path / file
                with open(file_path, "r") as f:
                    role_infos[file[:-5]] = yaml.safe_load(f)

        print_json(role_infos, title="è§’è‰²ä¿¡æ¯")
    else:
        print_message("promptsç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        role_infos = {}

    # åˆ›å»ºä¸‰ä¸ªè§’è‰²
    interviewer = InterviewerAgent(role_info=role_infos.get("interviewer"))
    candidate = CandidateAgent(role_info=role_infos.get("candidate"))
    hr = HRAgent(role_info=role_infos.get("hr"))

    # æ‰“å°è§’è‰²ä¿¡æ¯
    # res = interviewer.chat("è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    # rich_print(res)
    # res = candidate.chat("è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    # rich_print(res)
    # res = hr.chat("è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    # rich_print(res)

    # åˆ›å»ºé¢è¯•å¯¹è¯
    interview = InterviewConversation(interviewer, candidate, hr)

    # # å¼€å§‹é¢è¯•
    conversation_result = interview.chat()
    # æ‰“å°å¯¹è¯ç»“æœ
    print_message(conversation_result, title="å¯¹è¯ç»“æœ", use_panel=True)

    # æ‰“å°æœ€ç»ˆç»“æœ
    print_message("\n=== é¢è¯•æ€»ç»“ ===")
    hr_evaluations = interview.context_manager.get_hr_evaluations()
    for i, eval_data in enumerate(hr_evaluations, 1):
        print_message(f"hrçš„è¯„ä¼°[{i}]: {eval_data}")

    result_summary = interview.context_manager.get_result_summary()
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    with open(f"interview_result-{interview.candidate.id}.txt", "w") as f:
        f.write("\n=== å…³é”®æœ‰æ•ˆé—®ç­”æ€»ç»“ ===\n")
        for i, summary in enumerate(result_summary, 1):
            f.write(f"æ€»ç»“[{i}]: {summary}\n")

    print("\n=== é¢è¯•æ€»ç»“ç»“æŸ ===")


def real_data_interview_simulation():
    """çœŸå®æ•°æ®é¢è¯•æ¨¡æ‹Ÿ - å€™é€‰äººä½¿ç”¨çœŸå®ç®€å†ä¸HRåŠ©æ‰‹å¯¹è¯"""
    try:
        print_message("ğŸ¤– çœŸå®æ•°æ®é¢è¯•æ¨¡æ‹Ÿ")
        print_message("=" * 50)

        # åˆå§‹åŒ–é¢è¯•åŠ©æ‰‹å’Œè¯„ä¼°åŠ©æ‰‹
        assistant = InterviewAssistant()
        eval_assistant = EvalAssistant()  # æ–°å¢è¯„ä¼°åŠ©æ‰‹

        # åŠ è½½å¹¶æ˜¾ç¤ºå€™é€‰äººæ•°æ®
        df = pd.read_csv("interview_data.csv")
        print_message("\nğŸ“‹ å¯ç”¨å€™é€‰äººåˆ—è¡¨ï¼š")

        valid_candidates = []
        for i, row in df.iterrows():
            # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦æœ‰æ•ˆ
            if not pd.isna(row.get("å€™é€‰äººè„±æ•ç®€å†")) and not pd.isna(
                row.get("å²—ä½è„±æ•jd")
            ):
                position = row.get("å²—ä½åç§°", "æœªçŸ¥å²—ä½")
                intelligence = row.get("è¯¥å²—ä½è¦æ±‚çš„èªæ˜åº¦ï¼ˆæ»¡åˆ†ååˆ†ï¼‰", "N/A")

                if pd.isna(position):
                    position = "æœªçŸ¥å²—ä½"
                if pd.isna(intelligence):
                    intelligence = "N/A"

                valid_candidates.append(i)
                print_message(f"{i}: {position} (è¦æ±‚èªæ˜åº¦: {intelligence})")

                # åªæ˜¾ç¤ºå‰15ä¸ª
                if len(valid_candidates) >= 15:
                    break

        if not valid_candidates:
            print_message("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å€™é€‰äººæ•°æ®")
            return

        # ç”¨æˆ·é€‰æ‹©å€™é€‰äºº
        try:
            record_id = int(input(f"\nè¯·é€‰æ‹©å€™é€‰äººåºå·: "))
            if record_id not in valid_candidates:
                print_message("âŒ æ— æ•ˆçš„åºå·")
                return
        except ValueError:
            print_message("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            return

        # åŠ è½½é€‰å®šçš„å€™é€‰äººæ•°æ®
        candidate_row = df.iloc[record_id]
        candidate_data = {
            "resume": str(candidate_row.get("å€™é€‰äººè„±æ•ç®€å†", "")),
            "jd": str(candidate_row.get("å²—ä½è„±æ•jd", "")),
            "position": str(candidate_row.get("å²—ä½åç§°", "æœªçŸ¥å²—ä½")),
            "intelligence_requirement": candidate_row.get(
                "è¯¥å²—ä½è¦æ±‚çš„èªæ˜åº¦ï¼ˆæ»¡åˆ†ååˆ†ï¼‰", 0
            ),
        }

        print_message(f"\nâœ… å·²é€‰æ‹©å€™é€‰äºº:")
        print_message(f"å²—ä½: {candidate_data['position']}")
        print_message(f"èªæ˜åº¦è¦æ±‚: {candidate_data['intelligence_requirement']}")
        print_message(f"ç®€å†é¢„è§ˆ: {candidate_data['resume'][:100]}...")
        print_message(f"JDé¢„è§ˆ: {candidate_data['jd'][:100]}...")

        # ç”Ÿæˆé¢è¯•é—®é¢˜
        print_message("\nğŸ¤– æ­£åœ¨ä¸ºæ­¤å€™é€‰äººç”Ÿæˆé’ˆå¯¹æ€§é¢è¯•é—®é¢˜...")
        questions_result = assistant.generate_interview_questions(
            resume=candidate_data["resume"],
            jd=candidate_data["jd"],
            focus_areas=["èªæ˜åº¦", "çš®å®", "å‹¤å¥‹"],
        )

        if "error" in questions_result:
            print_message(f"âŒ ç”Ÿæˆé¢è¯•é—®é¢˜å¤±è´¥: {questions_result['error']}")
            return

        # æ˜¾ç¤ºç”Ÿæˆçš„é¢è¯•æ–¹æ¡ˆ
        print_message("\nğŸ“‹ ç”Ÿæˆçš„é¢è¯•æ–¹æ¡ˆ:")
        print_message("=" * 60)
        questions_text = questions_result["generated_questions"]

        # æå–å¼€åœºé—®é¢˜å’Œæ ¸å¿ƒé—®é¢˜ï¼ˆç®€åŒ–æ˜¾ç¤ºï¼‰
        preview = (
            questions_text[:800] + "..."
            if len(questions_text) > 800
            else questions_text
        )
        print_message(preview)

        # è¯¢é—®æ˜¯å¦å¼€å§‹æ¨¡æ‹Ÿé¢è¯•
        start_interview = input("\nğŸ¯ æ˜¯å¦å¼€å§‹æ¨¡æ‹Ÿé¢è¯•å¯¹è¯? (y/n): ").lower()
        if start_interview != "y":
            print_message("é¢è¯•å‡†å¤‡å®Œæˆï¼Œå¯éšæ—¶å¼€å§‹")
            return

        # é€‰æ‹©é¢è¯•æ¨¡å¼
        print_message("\nğŸ­ è¯·é€‰æ‹©é¢è¯•æ¨¡å¼:")
        print_message("1. æ‰‹åŠ¨æ¨¡å¼ - æ‚¨äº²è‡ªå›ç­”é¢è¯•é—®é¢˜")
        print_message("2. Agentæ¨¡å¼ - AIå€™é€‰äººæ ¹æ®ç®€å†æ•°æ®è‡ªåŠ¨å›ç­”")

        mode_choice = input("è¯·é€‰æ‹©æ¨¡å¼ (1-2): ").strip()

        if mode_choice == "2":
            # Agentæ¨¡å¼ï¼šåˆ›å»ºåŸºäºçœŸå®æ•°æ®çš„å€™é€‰äººAgent
            print_message("\nğŸ¤– æ­£åœ¨åˆ›å»ºAIå€™é€‰äºº...")
            candidate_agent = RealDataCandidateAgent(candidate_data)
            agent_mode = True

            # æ˜¾ç¤ºAIå€™é€‰äººä¿¡æ¯æ‘˜è¦
            info_summary = candidate_agent.get_candidate_info_summary()
            print_message("âœ… AIå€™é€‰äººå·²å°±ç»ªï¼ŒåŸºäºä»¥ä¸‹ç®€å†èƒŒæ™¯:")
            print_message(f"   å²—ä½: {info_summary['position']}")
            print_message(
                f"   èªæ˜åº¦è¦æ±‚: {info_summary['intelligence_requirement']}/100"
            )
            print_message(f"   ç®€å†é¢„è§ˆ: {info_summary['resume_preview']}")
            print_message("\nğŸ­ AIå€™é€‰äººå°†æ ¹æ®ç®€å†èƒŒæ™¯æ™ºèƒ½å›ç­”é¢è¯•é—®é¢˜")
        else:
            # æ‰‹åŠ¨æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            agent_mode = False
            print_message("âœ… æ‰‹åŠ¨æ¨¡å¼å·²å¯ç”¨ï¼Œæ‚¨å°†äº²è‡ªå›ç­”é¢è¯•é—®é¢˜")

        # å¼€å§‹äº¤äº’å¼é¢è¯•
        print_message("\n" + "=" * 60)
        print_message("ğŸ¤ é¢è¯•å¼€å§‹!")
        print_message("=" * 60)
        print_message("æç¤º: è¾“å…¥ 'quit' ç»“æŸé¢è¯•")

        conversation_history = []
        round_count = 0
        max_rounds = 8  # æœ€å¤š8è½®å¯¹è¯

        # HRå¼€åœºç™½
        hr_opening = f"æ¬¢è¿æ¥åˆ°é¢è¯•ï¼æˆ‘æ˜¯HRï¼Œä»Šå¤©æˆ‘ä»¬å°†é’ˆå¯¹{candidate_data['position']}å²—ä½è¿›è¡Œé¢è¯•ã€‚è¯·æ”¾æ¾å¿ƒæƒ…ï¼Œå±•ç¤ºæ‚¨æœ€å¥½çš„ä¸€é¢ã€‚"
        print_message(f"\n[HRåŠ©æ‰‹]: {hr_opening}")
        conversation_history.append({"role": "HR", "content": hr_opening})

        while round_count < max_rounds:
            round_count += 1
            print_message(f"\n--- ç¬¬ {round_count} è½®å¯¹è¯ ---")

            # HRæé—® (åŸºäºç”Ÿæˆçš„é—®é¢˜å’Œå¯¹è¯å†å²)
            if round_count == 1:
                # ç¬¬ä¸€è½®ï¼Œä½¿ç”¨å¼€åœºé—®é¢˜
                hr_question = (
                    "é¦–å…ˆï¼Œè¯·æ‚¨ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼ŒåŒ…æ‹¬æ‚¨çš„æ•™è‚²èƒŒæ™¯å’Œä¸»è¦å·¥ä½œç»å†ã€‚"
                )
            else:
                # åç»­è½®æ¬¡ï¼ŒåŸºäºé¢è¯•æ–¹æ¡ˆå’Œå¯¹è¯å†å²ç”Ÿæˆé—®é¢˜
                context_for_hr = f"""
åŸºäºä»¥ä¸‹é¢è¯•æ–¹æ¡ˆå’Œå¯¹è¯å†å²ï¼Œè¯·ä½œä¸ºHRé¢è¯•å®˜æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜ï¼š

é¢è¯•æ–¹æ¡ˆæ‘˜è¦:
{questions_text[:1000]}

å½“å‰å¯¹è¯å†å²:
{format_conversation_history(conversation_history[-4:])}  # åªä½¿ç”¨æœ€è¿‘4è½®å¯¹è¯

è¯·æå‡ºä¸€ä¸ªé’ˆå¯¹æ€§çš„é—®é¢˜ï¼Œé‡ç‚¹è¯„ä¼°å€™é€‰äººçš„èªæ˜åº¦ã€çš®å®æˆ–å‹¤å¥‹ç¨‹åº¦ã€‚é—®é¢˜è¦å…·ä½“ã€æœ‰æ·±åº¦ã€‚
"""
                try:
                    model = Model()
                    response = model.chat([user(content=context_for_hr)])
                    hr_question = assistant._extract_response_text(response)

                    # æ¸…ç†HRé—®é¢˜æ ¼å¼
                    if hr_question.startswith("[HR"):
                        hr_question = hr_question.split(":", 1)[1].strip()
                    elif hr_question.startswith("HR:"):
                        hr_question = hr_question.split(":", 1)[1].strip()

                except Exception as e:
                    print_message(f"âš ï¸ ç”Ÿæˆé—®é¢˜æ—¶å‡ºé”™: {e}")
                    # ä½¿ç”¨é¢„è®¾é—®é¢˜
                    default_questions = [
                        "èƒ½å¦è¯¦ç»†è¯´è¯´æ‚¨åœ¨å¤„ç†å›°éš¾é¡¹ç›®æ—¶çš„å…·ä½“ç»å†ï¼Ÿ",
                        "å‡å¦‚é‡åˆ°å·¥ä½œå‹åŠ›å¾ˆå¤§çš„æƒ…å†µï¼Œæ‚¨é€šå¸¸å¦‚ä½•åº”å¯¹ï¼Ÿ",
                        "æ‚¨è®¤ä¸ºè‡ªå·±æœ€å¤§çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿè¯·ä¸¾ä¸ªå…·ä½“ä¾‹å­ã€‚",
                        "æè¿°ä¸€æ¬¡æ‚¨ä¸»åŠ¨å­¦ä¹ æ–°æŠ€èƒ½çš„ç»å†ã€‚",
                    ]
                    hr_question = default_questions[
                        min(round_count - 2, len(default_questions) - 1)
                    ]

            print_message(f"[HRåŠ©æ‰‹]: {hr_question}")
            conversation_history.append({"role": "HR", "content": hr_question})

            # å€™é€‰äººå›ç­” - æ ¹æ®æ¨¡å¼é€‰æ‹©
            if agent_mode:
                # Agentæ¨¡å¼ï¼šAIå€™é€‰äººè‡ªåŠ¨å›ç­”
                print_message("\n[AIå€™é€‰äººæ€è€ƒä¸­...]")
                candidate_answer = candidate_agent.answer_question(hr_question)
                print_message(f"[AIå€™é€‰äºº]: {candidate_answer}")
            else:
                # æ‰‹åŠ¨æ¨¡å¼ï¼šç”¨æˆ·è¾“å…¥å›ç­”
                print_message("\n[æ‚¨çš„å›ç­”]:")
                candidate_answer = input(">> ").strip()

                if candidate_answer.lower() == "quit":
                    print_message("é¢è¯•ç»“æŸï¼Œæ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼")
                    break

                if not candidate_answer:
                    print_message("âš ï¸ è¯·è¾“å…¥æ‚¨çš„å›ç­”")
                    continue

            conversation_history.append({"role": "å€™é€‰äºº", "content": candidate_answer})

            # HRè¯„ä¼° - ä½¿ç”¨ä¸“ä¸šè¯„ä¼°åŠ©æ‰‹
            print_message("\n[HRè¯„ä¼°ä¸­...]")

            # ä½¿ç”¨EvalAssistantè¿›è¡Œè¯„ä¼°
            eval_result = eval_assistant.evaluate_single_response(
                question=hr_question,
                answer=candidate_answer,
                candidate_info=candidate_data,
                question_intent="",  # å¯ä»¥æ ¹æ®é¢è¯•æ–¹æ¡ˆæå–é—®é¢˜æ„å›¾
            )

            evaluation = eval_result.get("evaluation", "è¯„ä¼°å¤±è´¥")
            print_message(f"\n[HRè¯„ä¼°]: {evaluation}")

            # ä¿å­˜è¯„ä¼°åˆ°å¯¹è¯å†å²
            conversation_history.append({"role": "HRè¯„ä¼°", "content": evaluation})

        # é¢è¯•æ€»ç»“
        print_message("\n" + "=" * 60)
        print_message("ğŸ“‹ é¢è¯•æ€»ç»“")
        print_message("=" * 60)

        # ä¿å­˜é¢è¯•è®°å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        interview_record = {
            "candidate_info": candidate_data,
            "interview_questions_plan": questions_result,
            "conversation_history": conversation_history,
            "interview_time": timestamp,
            "total_rounds": round_count,
            "interview_mode": "agent" if agent_mode else "manual",
            "mode_description": "AIå€™é€‰äººè‡ªåŠ¨å›ç­”" if agent_mode else "ç”¨æˆ·æ‰‹åŠ¨å›ç­”",
        }

        record_file = f"real_data_interview_{timestamp}.json"
        try:
            import json

            with open(record_file, "w", encoding="utf-8") as f:
                json.dump(interview_record, f, ensure_ascii=False, indent=2)
            print_message(f"ğŸ“‹ é¢è¯•è®°å½•å·²ä¿å­˜åˆ°: {record_file}")
        except Exception as e:
            print_message(f"âš ï¸ ä¿å­˜é¢è¯•è®°å½•å¤±è´¥: {e}")

        # ç”Ÿæˆæœ€ç»ˆè¯„ä¼°
        print_message("\nğŸ¯ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç»¼åˆè¯„ä¼°...")

        try:
            # ä½¿ç”¨EvalAssistantç”Ÿæˆæœ€ç»ˆè¯„ä¼°
            final_result = eval_assistant.generate_final_evaluation(
                candidate_info=candidate_data, conversation_history=conversation_history
            )

            final_evaluation = final_result.get("final_evaluation", "è¯„ä¼°å¤±è´¥")
            avg_scores = final_result.get("average_scores", {})

            print_message("\n" + "=" * 80)
            print_message("ğŸ¯ æœ€ç»ˆç»¼åˆè¯„ä¼°ä¸å¤ç›˜")
            print_message("=" * 80)
            print_message(final_evaluation)

            print_message("\nğŸ“Š å„è½®è¯„ä¼°å¹³å‡åˆ†:")
            print_message(f"èªæ˜åº¦: {avg_scores.get('èªæ˜åº¦', 0)}/100")
            print_message(f"çš®å®: {avg_scores.get('çš®å®', 0)}/100")
            print_message(f"å‹¤å¥‹: {avg_scores.get('å‹¤å¥‹', 0)}/100")

            # æ›´æ–°é¢è¯•è®°å½•ï¼ŒåŒ…å«è¯„ä¼°è¯¦æƒ…
            interview_record["evaluation_details"] = {
                "round_evaluations": eval_assistant.round_evaluations,
                "final_evaluation": final_result,
                "average_scores": avg_scores,
            }

        except Exception as e:
            print_message(f"âš ï¸ ç”Ÿæˆæœ€ç»ˆè¯„ä¼°æ—¶å‡ºé”™: {e}")
            print_message("æ„Ÿè°¢å‚ä¸æœ¬æ¬¡é¢è¯•ï¼")

    except ImportError as e:
        print_message(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
        print_message("è¯·ç¡®è®¤ interview_assistant.py æ–‡ä»¶å­˜åœ¨")
    except FileNotFoundError:
        print_message("âŒ æœªæ‰¾åˆ° interview_data.csv æ–‡ä»¶")
    except Exception as e:
        print_message(f"âŒ çœŸå®æ•°æ®é¢è¯•æ¨¡æ‹Ÿå¤±è´¥: {e}")
        print_message(traceback.format_exc())


def format_conversation_history(history):
    """æ ¼å¼åŒ–å¯¹è¯å†å²"""
    formatted = ""
    for msg in history:
        formatted += f"{msg['role']}: {msg['content']}\n\n"
    return formatted
    # # è¯»å– prompts ç›®å½• ä¸‹çš„ yamlé…ç½®æ–‡ä»¶
    # dir_path = Path("prompts")
    # role_infos = {}

    # # æ£€æŸ¥promptsç›®å½•æ˜¯å¦å­˜åœ¨
    # if dir_path.exists():
    #     files = [f.name for f in dir_path.iterdir() if f.is_file()]
    #     print(f"æ–‡ä»¶åˆ—è¡¨: {files}")
    #     for file in files:
    #         if file.endswith(".yaml"):
    #             file_path = dir_path / file
    #             with open(file_path, "r") as f:
    #                 role_infos[file[:-5]] = yaml.safe_load(f)

    #     print_json(role_infos, title="è§’è‰²ä¿¡æ¯")
    # else:
    #     print_message("promptsç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    #     role_infos = {}

    # # åˆ›å»ºä¸‰ä¸ªè§’è‰²
    # interviewer = InterviewerAgent(role_info=role_infos.get("interviewer"))
    # candidate = CandidateAgent(role_info=role_infos.get("candidate"))
    # hr = HRAgent(role_info=role_infos.get("hr"))

    # # æ‰“å°è§’è‰²ä¿¡æ¯
    # # res = interviewer.chat("è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    # # rich_print(res)
    # # res = candidate.chat("è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    # # rich_print(res)
    # # res = hr.chat("è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
    # # rich_print(res)

    # # åˆ›å»ºé¢è¯•å¯¹è¯
    # interview = InterviewConversation(interviewer, candidate, hr)

    # # # å¼€å§‹é¢è¯•
    # conversation_result = interview.chat()
    # # æ‰“å°å¯¹è¯ç»“æœ
    # print_message(conversation_result, title="å¯¹è¯ç»“æœ", use_panel=True)

    # # æ‰“å°æœ€ç»ˆç»“æœ
    # print_message("\n=== é¢è¯•æ€»ç»“ ===")
    # hr_evaluations = interview.context_manager.get_hr_evaluations()
    # for i, eval_data in enumerate(hr_evaluations, 1):
    #     print_message(f"hrçš„è¯„ä¼°[{i}]: {eval_data}")

    # result_summary = interview.context_manager.get_result_summary()
    # # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    # with open(f"interview_result-{interview.candidate.id}.txt", "w") as f:
    #     f.write("\n=== å…³é”®æœ‰æ•ˆé—®ç­”æ€»ç»“ ===\n")
    #     for i, summary in enumerate(result_summary, 1):
    #         f.write(f"æ€»ç»“[{i}]: {summary}\n")

    # print("\n=== é¢è¯•æ€»ç»“ç»“æŸ ===")


def extract_interview_experience():
    """æå–é¢è¯•ç»éªŒ"""
    print_message("ğŸ§  å¼€å§‹æå–é¢è¯•ç»éªŒ...")

    try:
        from interview_processor import InterviewDataProcessor

        # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        processor = InterviewDataProcessor("interview_data.csv")

        # æ˜¾ç¤ºcheckpointçŠ¶æ€
        print_message("\nğŸ“ CheckpointçŠ¶æ€:")
        experience_files = processor.list_experience_files()
        print_message(f"ğŸ“ ç°æœ‰ç»éªŒæ–‡ä»¶: {len(experience_files)} ä¸ª")
        for exp_file in experience_files[-3:]:  # æ˜¾ç¤ºæœ€æ–°3ä¸ª
            print_message(
                f"  - {exp_file['filename']}: record_{exp_file['record_id']}, {exp_file['timestamp'][:10]}"
            )

        # è·å–è®°å½•é€‰æ‹©å’Œæ€»ç»“æ¨¡å¼ï¼ˆä»…åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ï¼‰
        import sys

        selected_indices = None
        summary_mode = "incremental"  # é»˜è®¤å¢é‡æ¨¡å¼

        if sys.stdin.isatty():
            try:
                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                total_valid = processor.display_data_preview()

                if total_valid == 0:
                    print_message("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ä¾›é€‰æ‹©")
                    return None

                # è·å–ç”¨æˆ·é€‰æ‹©
                selection_input = input(
                    f"\nğŸ“ è¯·è¾“å…¥è¦åˆ†æçš„è®°å½•åºå· (é»˜è®¤éšæœºé€‰æ‹©5æ¡): "
                ).strip()

                if selection_input:
                    selected_indices = processor._parse_indices_input(
                        selection_input, total_valid
                    )
                    if not selected_indices:
                        print_message("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
                        selected_indices = None

                # é€‰æ‹©æ€»ç»“æ¨¡å¼
                print_message("\nğŸ“‹ é€‰æ‹©æ€»ç»“æ¨¡å¼:")
                print_message("1. å¢é‡æ›´æ–° (incremental) - é»˜è®¤ï¼Œæ–°ç»éªŒä¸å·²æœ‰ç»éªŒåˆå¹¶")
                print_message("2. æ¸©æ•…çŸ¥æ–° (review) - åŒ…å«å†å²ç»éªŒçš„é‡æ–°æ€»ç»“")
                print_message("3. å…¨é‡é‡æ–°æ€»ç»“ (full_refresh) - å®Œå…¨é‡æ–°åˆ†ææ‰€æœ‰ç»éªŒ")

                mode_input = input("è¯·é€‰æ‹©æ¨¡å¼ (1-3, é»˜è®¤1): ").strip()
                mode_map = {"1": "incremental", "2": "review", "3": "full_refresh"}
                summary_mode = mode_map.get(mode_input, "incremental")

                print_message(f"âœ… å·²é€‰æ‹©æ¨¡å¼: {summary_mode}")

            except (EOFError, ValueError) as e:
                print_message(f"ä½¿ç”¨é»˜è®¤è®¾ç½®: éšæœºé€‰æ‹©5æ¡è®°å½•, æ¨¡å¼: {summary_mode}")

        # æå–ç»éªŒ
        experience_data = processor.extract_interview_experience(
            selected_indices=selected_indices,
            resume_from_checkpoint=False,  # æ–°è®¾è®¡ä¸éœ€è¦checkpointæ¢å¤
            summary_mode=summary_mode,
        )

        if "error" in experience_data:
            print_message(f"âŒ æå–å¤±è´¥: {experience_data['error']}")
            return None

        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print_message("\nğŸ“Š ç»éªŒæå–ç»“æœæ‘˜è¦:")
        print_message(f"æ€»è®°å½•æ•°: {experience_data['total_records']}")
        print_message(f"æœ‰æ•ˆè®°å½•æ•°: {experience_data['valid_records']}")
        print_message(f"é‡‡æ ·è®°å½•æ•°: {experience_data['sampled_records']}")
        print_message(f"æˆåŠŸæå–: {experience_data['successful_extractions']}")
        print_message(f"æ€»ç»“æ¨¡å¼: {experience_data['summary_mode']}")

        # æ˜¾ç¤ºtokenç»Ÿè®¡
        if "token_stats" in experience_data:
            token_stats = experience_data["token_stats"]
            print_message("\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
            print_message(f"è¾“å…¥tokens: {token_stats['total_input_tokens']:,}")
            print_message(f"è¾“å‡ºtokens: {token_stats['total_output_tokens']:,}")
            print_message(
                f"æ€»tokens: {token_stats['total_input_tokens'] + token_stats['total_output_tokens']:,}"
            )
            print_message(f"APIè°ƒç”¨æ¬¡æ•°: {token_stats['api_calls']}")
            print_message(f"é¢„ä¼°æ€»æˆæœ¬: ${token_stats['total_cost']:.4f}")

        # æ˜¾ç¤ºæ•´åˆåçš„ç»éªŒï¼ˆæˆªå–å‰500å­—ç¬¦ï¼‰
        if "integrated_experience" in experience_data:
            integrated_exp = experience_data["integrated_experience"]
            preview = (
                integrated_exp[:500] + "..."
                if len(integrated_exp) > 500
                else integrated_exp
            )
            print_message(f"\nğŸ¯ æ•´åˆç»éªŒé¢„è§ˆ:\n{preview}")

        # ä¿å­˜æŠ¥å‘Š
        report_path = processor.save_experience_report(experience_data)

        if sys.stdin.isatty():
            try:
                view_detail = input("\nğŸ‘€ æ˜¯å¦æŸ¥çœ‹è¯¦ç»†ç»éªŒå†…å®¹? (y/n): ").lower()
                if view_detail == "y" and "integrated_experience" in experience_data:
                    print_message("\nğŸ“– å®Œæ•´ç»éªŒå†…å®¹:")
                    print_message(experience_data["integrated_experience"])
            except EOFError:
                print_message("\nğŸ’¡ åœ¨éäº¤äº’å¼ç¯å¢ƒä¸­è¿è¡Œï¼Œè·³è¿‡è¯¦ç»†æŸ¥çœ‹")

        return experience_data

    except ImportError as e:
        print_message(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
        print_message("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print_message(traceback.format_exc())
    except Exception as e:
        print_message(f"âŒ æå–ç»éªŒå¤±è´¥: {e}")
        print_message("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print_message(traceback.format_exc())
        return None


def analyze_interview_data():
    """åˆ†æé¢è¯•æ•°æ®"""
    print_message("ğŸ” å¼€å§‹åˆ†æé¢è¯•æ•°æ®...")

    try:
        from interview_processor import InterviewDataProcessor

        # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        processor = InterviewDataProcessor("interview_data.csv")

        # è·å–åŸºæœ¬ä¿¡æ¯
        basic_info = processor.get_basic_info()
        print("\nğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print_json(basic_info)

        # åˆ†æå²—ä½åˆ†å¸ƒ
        position_analysis = processor.analyze_positions()
        print_message("\nğŸ“ˆ å²—ä½åˆ†æç»“æœ:")
        print_message(position_analysis)

        # åˆ†æé¢è¯•ç»“æœ
        interview_results = processor.analyze_interview_results()
        print_message("\nğŸ“ˆ é¢è¯•ç»“æœåˆ†æ:")
        print_json(interview_results)

        # æœç´¢ç‰¹å®šå€™é€‰äººï¼ˆä»…åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ï¼‰
        import sys

        if sys.stdin.isatty():  # æ£€æŸ¥æ˜¯å¦åœ¨äº¤äº’å¼ç»ˆç«¯ä¸­
            try:
                search_keyword = input(
                    "\nğŸ” è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ä¾‹å¦‚ï¼šå¸‚åœºã€é”€å”®ã€æŠ€æœ¯): "
                )
                if search_keyword:
                    candidates = processor.search_candidates(search_keyword)
                    print_message(f"\næ‰¾åˆ° {len(candidates)} ä¸ªç›¸å…³å€™é€‰äºº")
                    if len(candidates) > 0:
                        print_message("å‰3ä¸ªå€™é€‰äººä¿¡æ¯:")
                        for i in range(min(3, len(candidates))):
                            candidate_info = processor.extract_candidate_info(
                                candidates.index[i]
                            )
                            print_message(f"\nå€™é€‰äºº {i + 1}:")
                            print_message(
                                f"å²—ä½: {candidate_info['raw_data'].get('å²—ä½åç§°', 'æœªçŸ¥')}"
                            )
                            if candidate_info["resume_info"]:
                                print_message(
                                    f"ç®€å†ä¿¡æ¯: {candidate_info['resume_info']}"
                                )
            except EOFError:
                print_message("\nâš ï¸ æ£€æµ‹åˆ°éäº¤äº’å¼ç¯å¢ƒï¼Œè·³è¿‡æœç´¢åŠŸèƒ½")
        else:
            print_message("\nğŸ’¡ åœ¨éäº¤äº’å¼ç¯å¢ƒä¸­è¿è¡Œï¼Œè·³è¿‡æœç´¢åŠŸèƒ½")

        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆä»…åœ¨äº¤äº’å¼ç¯å¢ƒä¸­ï¼‰
        if sys.stdin.isatty():
            try:
                generate_viz = input("\nğŸ“Š æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨? (y/n): ").lower()
                if generate_viz == "y":
                    processor.plot_position_distribution()

                # å¯¼å‡ºæŠ¥å‘Š
                export_report = input("\nğŸ“‹ æ˜¯å¦å¯¼å‡ºåˆ†ææŠ¥å‘Š? (y/n): ").lower()
                if export_report == "y":
                    report_path = processor.export_analysis_report()
                    print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {report_path}")
            except EOFError:
                print_message("\nâš ï¸ æ£€æµ‹åˆ°éäº¤äº’å¼ç¯å¢ƒï¼Œè·³è¿‡å¯è§†åŒ–å’Œå¯¼å‡ºåŠŸèƒ½")
        else:
            print_message("\nğŸ’¡ åœ¨éäº¤äº’å¼ç¯å¢ƒä¸­è¿è¡Œï¼Œè·³è¿‡å¯è§†åŒ–å’Œå¯¼å‡ºåŠŸèƒ½")

        return processor

    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        print("è¯·å…ˆè¿è¡Œ: uv add pandas matplotlib seaborn")
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        print("è¯·ç¡®è®¤ interview_data.csv æ–‡ä»¶å­˜åœ¨")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        return None


def interview_assistant_mode():
    """é¢è¯•è¾…åŠ©è¿½é—®æ¨¡å¼"""
    try:
        from interview_assistant import InterviewAssistant

        print_message("ğŸ¤– é¢è¯•è¾…åŠ©è¿½é—®ç³»ç»Ÿ")
        print_message("=" * 50)

        assistant = InterviewAssistant()

        while True:
            choice = input(
                """
è¯·é€‰æ‹©åŠŸèƒ½ï¼š
1. åŸºäºCSVæ•°æ®ç”Ÿæˆé¢è¯•é—®é¢˜
2. æ‰‹åŠ¨è¾“å…¥ç®€å†å’ŒJDç”Ÿæˆé—®é¢˜
3. å€™é€‰äººåŒ¹é…åº¦åˆ†æ
4. è¿”å›ä¸»èœå•

è¯·è¾“å…¥é€‰æ‹© (1-4): """
            )

            if choice == "1":
                generate_questions_from_csv(assistant)
            elif choice == "2":
                generate_questions_manual(assistant)
            elif choice == "3":
                analyze_candidate_fit_manual(assistant)
            elif choice == "4":
                break
            else:
                print_message("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
        print("è¯·ç¡®è®¤ interview_assistant.py æ–‡ä»¶å­˜åœ¨")
    except Exception as e:
        print(f"âŒ é¢è¯•è¾…åŠ©ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print(traceback.format_exc())


def generate_questions_from_csv(assistant: "InterviewAssistant"):
    """ä»CSVæ•°æ®ç”Ÿæˆé¢è¯•é—®é¢˜"""
    try:
        # åŠ è½½å¹¶æ˜¾ç¤ºæ•°æ®
        candidate_data = assistant.load_candidate_data()
        if not candidate_data:
            print("âŒ æ— æ³•åŠ è½½å€™é€‰äººæ•°æ®")
            return

        # æ˜¾ç¤ºå¯ç”¨çš„å€™é€‰äººåˆ—è¡¨
        import pandas as pd

        df = pd.read_csv("interview_data.csv")
        print("\nğŸ“‹ å¯ç”¨å€™é€‰äººåˆ—è¡¨ï¼š")
        for i, row in df.iterrows():
            position = row.get("å²—ä½åç§°", "æœªçŸ¥å²—ä½")
            intelligence = row.get("è¯¥å²—ä½è¦æ±‚çš„èªæ˜åº¦ï¼ˆæ»¡åˆ†ååˆ†ï¼‰", "N/A")

            # å¤„ç†NaNå€¼
            if pd.isna(position):
                position = "æœªçŸ¥å²—ä½"
            if pd.isna(intelligence):
                intelligence = "N/A"

            # åªæ˜¾ç¤ºå‰20ä¸ªæœ‰æ•ˆè®°å½•
            if i < 20 and not pd.isna(row.get("å€™é€‰äººè„±æ•ç®€å†")):
                print(f"{i}: {position} (è¦æ±‚èªæ˜åº¦: {intelligence})")
            elif i >= 20:
                break

        # ç”¨æˆ·é€‰æ‹©å€™é€‰äºº
        try:
            record_id = int(input(f"\nè¯·é€‰æ‹©å€™é€‰äººåºå· (0-19): "))
            if record_id < 0 or record_id >= 20:
                print("âŒ æ— æ•ˆçš„åºå·")
                return
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            return

        # åŠ è½½é€‰å®šçš„å€™é€‰äººæ•°æ®
        candidate_data = assistant.load_candidate_data(record_id=record_id)
        if not candidate_data:
            print("âŒ åŠ è½½å€™é€‰äººæ•°æ®å¤±è´¥")
            return

        print(f"\nâœ… å·²é€‰æ‹©å€™é€‰äºº: {candidate_data.get('position', 'æœªçŸ¥å²—ä½')}")
        print(f"ğŸ“ ç®€å†é¢„è§ˆ: {candidate_data['resume'][:100]}...")
        print(f"ğŸ’¼ JDé¢„è§ˆ: {candidate_data['jd'][:100]}...")

        # é€‰æ‹©è¯„ä¼°é‡ç‚¹
        focus_areas = select_focus_areas()

        # ç”Ÿæˆé¢è¯•é—®é¢˜
        result = assistant.generate_interview_questions(
            resume=candidate_data["resume"],
            jd=candidate_data["jd"],
            focus_areas=focus_areas,
        )

        if "error" not in result:
            # æ˜¾ç¤ºç”Ÿæˆçš„é—®é¢˜
            print("\n" + "=" * 60)
            print("ğŸ¯ ç”Ÿæˆçš„é¢è¯•é—®é¢˜æ–¹æ¡ˆ:")
            print("=" * 60)
            print(result["generated_questions"])

            # ä¿å­˜ç»“æœï¼Œä¼ é€’å€™é€‰äººID
            output_path = assistant.save_interview_plan(
                result, candidate_id=f"record_{record_id}"
            )

            # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ
            token_usage = result.get("token_usage", {})
            print(f"\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
            print(f"è¾“å…¥tokens: {token_usage.get('input_tokens', 0):,}")
            print(f"è¾“å‡ºtokens: {token_usage.get('output_tokens', 0):,}")
            print(f"æ€»tokens: {token_usage.get('total_tokens', 0):,}")
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {result['error']}")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆé¢è¯•é—®é¢˜å¤±è´¥: {e}")
        print(traceback.format_exc())


def generate_questions_manual(assistant: "InterviewAssistant"):
    """æ‰‹åŠ¨è¾“å…¥ç®€å†å’ŒJDç”Ÿæˆé—®é¢˜"""
    try:
        print("\nğŸ“ è¯·è¾“å…¥å€™é€‰äººä¿¡æ¯:")

        print("\n1. è¯·è¾“å…¥å€™é€‰äººç®€å† (è¾“å…¥å®ŒæˆåæŒ‰Enterï¼Œç„¶åè¾“å…¥'END'ç»“æŸ):")
        resume_lines = []
        while True:
            line = input()
            if line.strip().upper() == "END":
                break
            resume_lines.append(line)
        resume = "\n".join(resume_lines)

        if not resume.strip():
            print("âŒ ç®€å†ä¸èƒ½ä¸ºç©º")
            return

        print("\n2. è¯·è¾“å…¥å²—ä½æè¿° (è¾“å…¥å®ŒæˆåæŒ‰Enterï¼Œç„¶åè¾“å…¥'END'ç»“æŸ):")
        jd_lines = []
        while True:
            line = input()
            if line.strip().upper() == "END":
                break
            jd_lines.append(line)
        jd = "\n".join(jd_lines)

        if not jd.strip():
            print("âŒ å²—ä½æè¿°ä¸èƒ½ä¸ºç©º")
            return

        # é€‰æ‹©è¯„ä¼°é‡ç‚¹
        focus_areas = select_focus_areas()

        # ç”Ÿæˆé¢è¯•é—®é¢˜
        result = assistant.generate_interview_questions(
            resume=resume, jd=jd, focus_areas=focus_areas
        )

        if "error" not in result:
            # æ˜¾ç¤ºç”Ÿæˆçš„é—®é¢˜
            print("\n" + "=" * 60)
            print("ğŸ¯ ç”Ÿæˆçš„é¢è¯•é—®é¢˜æ–¹æ¡ˆ:")
            print("=" * 60)
            print(result["generated_questions"])

            # ä¿å­˜ç»“æœï¼Œæ‰‹åŠ¨è¾“å…¥æ¨¡å¼ä½¿ç”¨manualæ ‡è¯†
            output_path = assistant.save_interview_plan(result, candidate_id="manual")

            # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ
            token_usage = result.get("token_usage", {})
            print(f"\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
            print(f"è¾“å…¥tokens: {token_usage.get('input_tokens', 0):,}")
            print(f"è¾“å‡ºtokens: {token_usage.get('output_tokens', 0):,}")
            print(f"æ€»tokens: {token_usage.get('total_tokens', 0):,}")
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {result['error']}")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆé¢è¯•é—®é¢˜å¤±è´¥: {e}")
        print(traceback.format_exc())


def analyze_candidate_fit_manual(assistant: "InterviewAssistant"):
    """æ‰‹åŠ¨åˆ†æå€™é€‰äººåŒ¹é…åº¦"""
    try:
        print("\nğŸ” å€™é€‰äººåŒ¹é…åº¦åˆ†æ")

        print("\n1. è¯·è¾“å…¥å€™é€‰äººç®€å† (è¾“å…¥å®ŒæˆåæŒ‰Enterï¼Œç„¶åè¾“å…¥'END'ç»“æŸ):")
        resume_lines = []
        while True:
            line = input()
            if line.strip().upper() == "END":
                break
            resume_lines.append(line)
        resume = "\n".join(resume_lines)

        if not resume.strip():
            print("âŒ ç®€å†ä¸èƒ½ä¸ºç©º")
            return

        print("\n2. è¯·è¾“å…¥å²—ä½æè¿° (è¾“å…¥å®ŒæˆåæŒ‰Enterï¼Œç„¶åè¾“å…¥'END'ç»“æŸ):")
        jd_lines = []
        while True:
            line = input()
            if line.strip().upper() == "END":
                break
            jd_lines.append(line)
        jd = "\n".join(jd_lines)

        if not jd.strip():
            print("âŒ å²—ä½æè¿°ä¸èƒ½ä¸ºç©º")
            return

        # åˆ†æåŒ¹é…åº¦
        result = assistant.analyze_candidate_fit(resume=resume, jd=jd)

        if "error" not in result:
            # æ˜¾ç¤ºåˆ†æç»“æœ
            print("\n" + "=" * 60)
            print("ğŸ“Š å€™é€‰äººåŒ¹é…åº¦åˆ†æç»“æœ:")
            print("=" * 60)
            print(result["fit_analysis"])

            # ä¿å­˜ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"candidate_fit_analysis_{timestamp}.json"
            try:
                import json

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ“‹ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜å¤±è´¥: {e}")

            # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ
            token_usage = result.get("token_usage", {})
            print(f"\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
            print(f"è¾“å…¥tokens: {token_usage.get('input_tokens', 0):,}")
            print(f"è¾“å‡ºtokens: {token_usage.get('output_tokens', 0):,}")
            print(f"æ€»tokens: {token_usage.get('total_tokens', 0):,}")
        else:
            print(f"âŒ åˆ†æå¤±è´¥: {result['error']}")

    except Exception as e:
        print(f"âŒ åŒ¹é…åº¦åˆ†æå¤±è´¥: {e}")
        print(traceback.format_exc())


def view_json_reports():
    """æŸ¥çœ‹JSONæŠ¥å‘Šå·¥å…·"""
    print_message("ğŸ“Š JSONæŠ¥å‘ŠæŸ¥çœ‹å™¨")
    print_message("=" * 50)

    try:
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶
        json_files = []

        # æ‰«ææ ¹ç›®å½•çš„JSONæ–‡ä»¶
        root_json_files = glob.glob("*.json")
        for file in root_json_files:
            json_files.append(("æ ¹ç›®å½•", file))

        # æ‰«æcheckpointsç›®å½•çš„JSONæ–‡ä»¶
        if os.path.exists("checkpoints"):
            checkpoint_files = glob.glob("checkpoints/*.json")
            for file in checkpoint_files:
                json_files.append(("checkpoints", file))

        if not json_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•JSONæŠ¥å‘Šæ–‡ä»¶")
            return

        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        print("ğŸ“ å¯ç”¨çš„JSONæŠ¥å‘Šæ–‡ä»¶:")
        print()

        # åˆ†ç±»æ˜¾ç¤º
        general_guidelines = []
        individual_experiences = []
        interview_plans = []
        other_files = []

        for category, file_path in json_files:
            if "general_interview_guidelines" in file_path:
                general_guidelines.append((category, file_path))
            elif "individual_interview_experience" in file_path:
                individual_experiences.append((category, file_path))
            elif "interview_plan" in file_path:
                interview_plans.append((category, file_path))
            else:
                other_files.append((category, file_path))

        file_index = 1
        all_files = []

        # æ˜¾ç¤ºé€šç”¨é¢è¯•æé—®ç»éªŒ
        if general_guidelines:
            print("ğŸ“š é€šç”¨é¢è¯•æé—®ç»éªŒ:")
            for category, file_path in general_guidelines:
                print(f"  {file_index}. {file_path}")
                all_files.append((category, file_path))
                file_index += 1
            print()

        # æ˜¾ç¤ºä¸ªäººé¢è¯•ç»éªŒæ€»ç»“
        if individual_experiences:
            print("ï¿½ ä¸ªäººé¢è¯•ç»éªŒæ€»ç»“:")
            for category, file_path in individual_experiences:
                filename = os.path.basename(file_path)
                print(f"  {file_index}. {filename}")
                all_files.append((category, file_path))
                file_index += 1
            print()

        # æ˜¾ç¤ºé¢è¯•æ–¹æ¡ˆ
        if interview_plans:
            print("ï¿½ é¢è¯•æ–¹æ¡ˆ:")
            for category, file_path in interview_plans:
                print(f"  {file_index}. {file_path}")
                all_files.append((category, file_path))
                file_index += 1
            print()

        # æ˜¾ç¤ºå…¶ä»–æ–‡ä»¶
        if other_files:
            print("ğŸ“„ å…¶ä»–JSONæ–‡ä»¶:")
            for category, file_path in other_files:
                print(f"  {file_index}. {file_path}")
                all_files.append((category, file_path))
                file_index += 1
            print()

        while True:
            choice = input(
                f"è¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æ–‡ä»¶ (1-{len(all_files)}), è¾“å…¥ 'l' é‡æ–°åˆ—å‡º, æˆ–è¾“å…¥ 'q' é€€å‡º: "
            ).strip()

            if choice.lower() == "q":
                break
            elif choice.lower() == "l":
                # é‡æ–°æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                print("\nğŸ“ å¯ç”¨çš„JSONæŠ¥å‘Šæ–‡ä»¶:")
                print()

                # é‡æ–°æ˜¾ç¤ºé€šç”¨é¢è¯•æé—®ç»éªŒ
                if general_guidelines:
                    print("ğŸ“š é€šç”¨é¢è¯•æé—®ç»éªŒ:")
                    for i, (category, file_path) in enumerate(general_guidelines, 1):
                        print(f"  {i}. {file_path}")
                    print()

                # é‡æ–°æ˜¾ç¤ºä¸ªäººé¢è¯•ç»éªŒæ€»ç»“
                if individual_experiences:
                    start_idx = len(general_guidelines) + 1
                    print("ğŸ‘¤ ä¸ªäººé¢è¯•ç»éªŒæ€»ç»“:")
                    for i, (category, file_path) in enumerate(
                        individual_experiences, start_idx
                    ):
                        filename = os.path.basename(file_path)
                        print(f"  {i}. {filename}")
                    print()

                # é‡æ–°æ˜¾ç¤ºé¢è¯•æ–¹æ¡ˆ
                if interview_plans:
                    start_idx = (
                        len(general_guidelines) + len(individual_experiences) + 1
                    )
                    print("ğŸ“‹ é¢è¯•æ–¹æ¡ˆ:")
                    for i, (category, file_path) in enumerate(
                        interview_plans, start_idx
                    ):
                        print(f"  {i}. {file_path}")
                    print()

                # é‡æ–°æ˜¾ç¤ºå…¶ä»–æ–‡ä»¶
                if other_files:
                    start_idx = (
                        len(general_guidelines)
                        + len(individual_experiences)
                        + len(interview_plans)
                        + 1
                    )
                    print("ï¿½ å…¶ä»–JSONæ–‡ä»¶:")
                    for i, (category, file_path) in enumerate(other_files, start_idx):
                        print(f"  {i}. {file_path}")
                    print()
                continue

            try:
                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(all_files):
                    category, file_path = all_files[choice_idx]
                    view_json_file(file_path, show_full_content=True)
                else:
                    print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
            except ValueError:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ã€'l' æˆ– 'q'")

    except Exception as e:
        print(f"âŒ æŸ¥çœ‹JSONæŠ¥å‘Šå¤±è´¥: {e}")
        print(traceback.format_exc())


def view_json_file(file_path, show_full_content=False):
    """æŸ¥çœ‹å•ä¸ªJSONæ–‡ä»¶"""
    try:
        print_message(f"\nğŸ“„ æ­£åœ¨æŸ¥çœ‹: {file_path}")
        print_message("=" * 60)

        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # æ ¹æ®æ–‡ä»¶ç±»å‹æ˜¾ç¤ºä¸åŒçš„ä¿¡æ¯
        if "general_interview_guidelines" in file_path:
            display_general_guidelines(data, show_full_content)
        elif "individual_interview_experience" in file_path:
            display_individual_experience(data, show_full_content)
        elif "interview_plan" in file_path:
            display_plan_report(data, show_full_content)
        else:
            display_generic_json(data, show_full_content)

        print_message("=" * 60)
        input("æŒ‰å›è½¦é”®ç»§ç»­...")

    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")


def display_general_guidelines(data, show_full_content=False):
    """æ˜¾ç¤ºé€šç”¨é¢è¯•æé—®ç»éªŒ"""
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {data.get('total_records', 'N/A')}")
    print(f"âœ… æœ‰æ•ˆè®°å½•æ•°: {data.get('valid_records', 'N/A')}")
    print(f"ğŸ¯ é‡‡æ ·è®°å½•æ•°: {data.get('sampled_records', 'N/A')}")
    print(f"ğŸ§  æˆåŠŸæå–æ•°: {data.get('successful_extractions', 'N/A')}")
    print(f"ğŸ“… æ€»ç»“æ¨¡å¼: {data.get('summary_mode', 'N/A')}")

    # Tokenç»Ÿè®¡
    if "token_stats" in data:
        tokens = data["token_stats"]
        print(f"\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
        print(f"  è¾“å…¥Tokens: {tokens.get('total_input_tokens', 0):,}")
        print(f"  è¾“å‡ºTokens: {tokens.get('total_output_tokens', 0):,}")
        print(f"  æ€»æˆæœ¬: ${tokens.get('total_cost', 0):.6f}")

    # æ–°æå–çš„ç»éªŒ
    if "new_experiences" in data and data["new_experiences"]:
        print(f"\n æ–°æå–çš„ç»éªŒ ({len(data['new_experiences'])}æ¡):")
        max_experiences = (
            len(data["new_experiences"])
            if show_full_content
            else min(3, len(data["new_experiences"]))
        )

        for i, exp in enumerate(data["new_experiences"][:max_experiences], 1):
            print(f"\n  [{i}] è®°å½•ID: {exp.get('record_id', 'N/A')}")
            resume = exp.get("resume_summary", "")
            if resume:
                if show_full_content:
                    print(f"      ç®€å†æ‘˜è¦: {resume}")
                else:
                    print(f"      ç®€å†æ‘˜è¦: {resume[:100]}...")
            print(f"      åˆ†ææ—¶é—´: {exp.get('analysis_time', 'N/A')}")

            # å¦‚æœæ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œä¹Ÿæ˜¾ç¤ºæå–çš„ç»éªŒ
            if show_full_content and "extracted_experience" in exp:
                print_message(f"      æå–çš„ç»éªŒ:\n{exp['extracted_experience']}")

        if not show_full_content and len(data["new_experiences"]) > 3:
            print(f"      ... è¿˜æœ‰ {len(data['new_experiences']) - 3} æ¡ç»éªŒ")

    # é›†æˆç»éªŒ
    if "integrated_experience" in data:
        exp_text = data["integrated_experience"]
        print(f"\nğŸ“š é›†æˆç»éªŒ{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

        if show_full_content:
            print_message(exp_text)
        else:
            lines = exp_text.split("\n")
            for line in lines[:10]:  # æ˜¾ç¤ºå‰10è¡Œ
                if line.strip():
                    print(f"    {line}")
            if len(lines) > 10:
                print(f"    ... (è¿˜æœ‰ {len(lines) - 10} è¡Œ)")


def display_individual_experience(data, show_full_content=False):
    """æ˜¾ç¤ºä¸ªäººé¢è¯•ç»éªŒæ€»ç»“"""
    print(f"ğŸ”„ è®°å½•ID: {data.get('record_id', 'N/A')}")
    print(f"ğŸ“ æ ·æœ¬åç§°: {data.get('sample_name', 'N/A')}")
    print(f"â° æ—¶é—´æˆ³: {data.get('timestamp', 'N/A')}")

    # ç»éªŒå†…å®¹
    if "experience" in data:
        exp = data["experience"]
        print(f"\nğŸ“‹ ç»éªŒå†…å®¹:")
        print(f"  è®°å½•ID: {exp.get('record_id', 'N/A')}")
        print(f"  åˆ†ææ—¶é—´: {exp.get('analysis_time', 'N/A')}")

        # ç®€å†æ‘˜è¦
        if "resume_summary" in exp:
            resume = exp["resume_summary"]
            print_message(
                f"\n  ğŸ‘¤ ç®€å†æ‘˜è¦{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:"
            )

            if show_full_content:
                print(f"      {resume}")
            else:
                lines = resume.split("\n")
                for line in lines[:3]:
                    if line.strip():
                        print(f"      {line}")
                if len(lines) > 3:
                    print(f"      ... (è¿˜æœ‰ {len(lines) - 3} è¡Œ)")

        # è¯„ä¼°å†…å®¹
        if "evaluation" in exp:
            evaluation = exp["evaluation"]
            print(f"\n  ğŸ“Š è¯„ä¼°{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")
            if show_full_content:
                print_message(f"      {evaluation}")
            else:
                print(f"      {evaluation[:200]}...")

        # æå–çš„ç»éªŒ
        if "extracted_experience" in exp:
            extracted = exp["extracted_experience"]
            print(f"\n  ğŸ§  æå–ç»éªŒ{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

            if show_full_content:
                print_message(extracted)
            else:
                lines = extracted.split("\n")
                for line in lines[:5]:
                    if line.strip():
                        print(f"      {line}")
                if len(lines) > 5:
                    print(f"      ... (è¿˜æœ‰ {len(lines) - 5} è¡Œ)")


def display_experience_report(data, show_full_content=False):
    """æ˜¾ç¤ºç»éªŒæå–æŠ¥å‘Š"""
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {data.get('total_records', 'N/A')}")
    print(f"âœ… æœ‰æ•ˆè®°å½•æ•°: {data.get('valid_records', 'N/A')}")
    print(f"ğŸ¯ é‡‡æ ·è®°å½•æ•°: {data.get('sampled_records', 'N/A')}")
    print(f"ğŸ§  æˆåŠŸæå–æ•°: {data.get('successful_extractions', 'N/A')}")
    print(f"ğŸ“… æ€»ç»“æ¨¡å¼: {data.get('summary_mode', 'N/A')}")

    # Tokenç»Ÿè®¡
    if "token_stats" in data:
        tokens = data["token_stats"]
        print(f"\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
        print(f"  è¾“å…¥Tokens: {tokens.get('total_input_tokens', 0):,}")
        print(f"  è¾“å‡ºTokens: {tokens.get('total_output_tokens', 0):,}")
        print(f"  æ€»æˆæœ¬: ${tokens.get('total_cost', 0):.6f}")

    # æ–°æå–çš„ç»éªŒ
    if "new_experiences" in data and data["new_experiences"]:
        print(f"\n æ–°æå–çš„ç»éªŒ ({len(data['new_experiences'])}æ¡):")
        max_experiences = (
            len(data["new_experiences"])
            if show_full_content
            else min(3, len(data["new_experiences"]))
        )

        for i, exp in enumerate(data["new_experiences"][:max_experiences], 1):
            print(f"\n  [{i}] è®°å½•ID: {exp.get('record_id', 'N/A')}")
            resume = exp.get("resume_summary", "")
            if resume:
                if show_full_content:
                    print_message(f"      ç®€å†æ‘˜è¦: {resume}")
                else:
                    print(f"      ç®€å†æ‘˜è¦: {resume[:100]}...")
            print(f"      åˆ†ææ—¶é—´: {exp.get('analysis_time', 'N/A')}")

            # å¦‚æœæ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œä¹Ÿæ˜¾ç¤ºæå–çš„ç»éªŒ
            if show_full_content and "extracted_experience" in exp:
                print_message(f"      æå–çš„ç»éªŒ:\n{exp['extracted_experience']}")

        if not show_full_content and len(data["new_experiences"]) > 3:
            print(f"      ... è¿˜æœ‰ {len(data['new_experiences']) - 3} æ¡ç»éªŒ")

    # é›†æˆç»éªŒ
    if "integrated_experience" in data:
        exp_text = data["integrated_experience"]
        print(f"\nğŸ“š é›†æˆç»éªŒ{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

        if show_full_content:
            print_message(exp_text)
        else:
            lines = exp_text.split("\n")
            for line in lines[:10]:  # æ˜¾ç¤ºå‰10è¡Œ
                if line.strip():
                    print(f"    {line}")
            if len(lines) > 10:
                print(f"    ... (è¿˜æœ‰ {len(lines) - 10} è¡Œ)")


def display_plan_report(data, show_full_content=False):
    """æ˜¾ç¤ºé¢è¯•è®¡åˆ’æŠ¥å‘Š"""
    print(f"ğŸ“… ç”Ÿæˆæ—¶é—´: {data.get('generation_time', 'N/A')}")

    # å€™é€‰äººç®€å†
    if "candidate_resume" in data:
        resume = data["candidate_resume"]
        print(f"\nğŸ‘¤ å€™é€‰äººç®€å†{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

        if show_full_content:
            print_message(resume)
        else:
            lines = resume.split("\n")
            for line in lines[:5]:
                if line.strip():
                    print(f"    {line}")
            if len(lines) > 5:
                print(f"    ... (è¿˜æœ‰ {len(lines) - 5} è¡Œ)")

    # èŒä½æè¿°
    if "job_description" in data:
        jd = data["job_description"]
        print(f"\nğŸ’¼ èŒä½æè¿°{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

        if show_full_content:
            print_message(jd)
        else:
            lines = jd.split("\n")
            for line in lines[:5]:
                if line.strip():
                    print(f"    {line}")
            if len(lines) > 5:
                print(f"    ... (è¿˜æœ‰ {len(lines) - 5} è¡Œ)")

    # å…³æ³¨é¢†åŸŸ
    if "focus_areas" in data:
        print(f"\nğŸ¯ å…³æ³¨é¢†åŸŸ: {', '.join(data['focus_areas'])}")

    # Tokenä½¿ç”¨æƒ…å†µ
    if "token_usage" in data:
        tokens = data["token_usage"]
        print(f"\nğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡:")
        print(f"  è¾“å…¥Tokens: {tokens.get('input_tokens', 0):,}")
        print(f"  è¾“å‡ºTokens: {tokens.get('output_tokens', 0):,}")
        print(f"  æ€»Tokens: {tokens.get('total_tokens', 0):,}")

    # ç”Ÿæˆçš„é—®é¢˜é¢„è§ˆ
    if "generated_questions" in data:
        questions = data["generated_questions"]
        print(f"\nâ“ ç”Ÿæˆçš„é—®é¢˜{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

        if show_full_content:
            print(questions)
        else:
            lines = questions.split("\n")
            for line in lines[:15]:
                if line.strip():
                    print(f"    {line}")
            if len(lines) > 15:
                print(f"    ... (è¿˜æœ‰ {len(lines) - 15} è¡Œ)")


def display_checkpoint_file(data, show_full_content=False):
    """æ˜¾ç¤ºcheckpointæ–‡ä»¶"""
    print(f"ğŸ”„ è®°å½•ID: {data.get('record_id', 'N/A')}")
    print(f"ğŸ“ æ ·æœ¬åç§°: {data.get('sample_name', 'N/A')}")
    print(f"â° æ—¶é—´æˆ³: {data.get('timestamp', 'N/A')}")

    # ç»éªŒå†…å®¹
    if "experience" in data:
        exp = data["experience"]
        print(f"\nğŸ“‹ ç»éªŒå†…å®¹:")
        print(f"  è®°å½•ID: {exp.get('record_id', 'N/A')}")
        print(f"  åˆ†ææ—¶é—´: {exp.get('analysis_time', 'N/A')}")

        # ç®€å†æ‘˜è¦
        if "resume_summary" in exp:
            resume = exp["resume_summary"]
            print(f"\n  ğŸ‘¤ ç®€å†æ‘˜è¦{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

            if show_full_content:
                print(f"      {resume}")
            else:
                lines = resume.split("\n")
                for line in lines[:3]:
                    if line.strip():
                        print(f"      {line}")
                if len(lines) > 3:
                    print(f"      ... (è¿˜æœ‰ {len(lines) - 3} è¡Œ)")

        # è¯„ä¼°å†…å®¹
        if "evaluation" in exp:
            evaluation = exp["evaluation"]
            print(f"\n  ğŸ“Š è¯„ä¼°{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")
            if show_full_content:
                print(f"      {evaluation}")
            else:
                print(f"      {evaluation[:200]}...")

        # æå–çš„ç»éªŒ
        if "extracted_experience" in exp:
            extracted = exp["extracted_experience"]
            print(f"\n  ğŸ§  æå–ç»éªŒ{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")

            if show_full_content:
                print(extracted)
            else:
                lines = extracted.split("\n")
                for line in lines[:5]:
                    if line.strip():
                        print(f"      {line}")
                if len(lines) > 5:
                    print(f"      ... (è¿˜æœ‰ {len(lines) - 5} è¡Œ)")


def display_generic_json(data, show_full_content=False):
    """æ˜¾ç¤ºé€šç”¨JSONæ•°æ®"""

    def print_value(key, value, indent=0, full_content=False):
        prefix = "  " * indent
        if isinstance(value, dict):
            print(f"{prefix}{key}:")
            items_to_show = (
                list(value.items()) if full_content else list(value.items())[:5]
            )

            for k, v in items_to_show:
                print_value(k, v, indent + 1, full_content)

            if not full_content and len(value) > 5:
                print(f"{prefix}  ... (è¿˜æœ‰ {len(value) - 5} ä¸ªé”®)")

        elif isinstance(value, list):
            print(f"{prefix}{key}: [åˆ—è¡¨ï¼Œ{len(value)} ä¸ªé¡¹ç›®]")
            items_to_show = value if full_content else value[:3]

            for i, item in enumerate(items_to_show):
                if isinstance(item, (dict, list)):
                    print(f"{prefix}  [{i}]: {type(item).__name__}")
                    if full_content and isinstance(item, dict):
                        for k, v in item.items():
                            print_value(k, v, indent + 2, full_content)
                else:
                    item_str = str(item)
                    if not full_content and len(item_str) > 100:
                        item_str = item_str[:100] + "..."
                    print(f"{prefix}  [{i}]: {item_str}")

            if not full_content and len(value) > 3:
                print(f"{prefix}  ... (è¿˜æœ‰ {len(value) - 3} ä¸ªé¡¹ç›®)")

        elif isinstance(value, str):
            if not full_content and len(value) > 200:
                print(f"{prefix}{key}: {value[:200]}...")
            else:
                print(f"{prefix}{key}: {value}")
        else:
            print(f"{prefix}{key}: {value}")

    print(f"ğŸ“„ JSONæ•°æ®{'å®Œæ•´å†…å®¹' if show_full_content else 'é¢„è§ˆ'}:")
    items_to_show = list(data.items()) if show_full_content else list(data.items())[:10]

    for key, value in items_to_show:
        print_value(key, value, full_content=show_full_content)

    if not show_full_content and len(data) > 10:
        print(f"  ... (è¿˜æœ‰ {len(data) - 10} ä¸ªé”®)")


def select_focus_areas():
    """é€‰æ‹©è¯„ä¼°é‡ç‚¹é¢†åŸŸ"""
    print("\nğŸ“‹ è¯·é€‰æ‹©è¯„ä¼°é‡ç‚¹ (å¯å¤šé€‰ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 1,2,3):")
    print("1. èªæ˜åº¦")
    print("2. çš®å®")
    print("3. å‹¤å¥‹")
    print("4. å…¨éƒ¨ (é»˜è®¤)")

    choice = input("è¯·è¾“å…¥é€‰æ‹©: ").strip()

    if not choice or choice == "4":
        return ["èªæ˜åº¦", "çš®å®", "å‹¤å¥‹"]

    focus_map = {"1": "èªæ˜åº¦", "2": "çš®å®", "3": "å‹¤å¥‹"}

    try:
        selected = [
            focus_map[c.strip()] for c in choice.split(",") if c.strip() in focus_map
        ]
        if not selected:
            print("âš ï¸ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤ (å…¨éƒ¨)")
            return ["èªæ˜åº¦", "çš®å®", "å‹¤å¥‹"]
        return selected
    except:
        print("âš ï¸ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤ (å…¨éƒ¨)")
        return ["èªæ˜åº¦", "çš®å®", "å‹¤å¥‹"]


def main():
    print_message("ğŸ¯ é¢è¯•æ¨¡æ‹Ÿç³»ç»Ÿ")
    print_message("=" * 50)

    try:
        choice = input(
            """
è¯·é€‰æ‹©åŠŸèƒ½ï¼š
1. è¿è¡Œé¢è¯•æ¨¡æ‹Ÿ
2. åˆ†æé¢è¯•æ•°æ®
3. æå–é¢è¯•ç»éªŒ
4. é¢è¯•è¾…åŠ©è¿½é—®
5. æŸ¥çœ‹JSONæŠ¥å‘Š
6. é€€å‡º

è¯·è¾“å…¥é€‰æ‹© (1-6): """
        )

        if choice == "1":
            interview_scene()
        elif choice == "2":
            analyze_interview_data()
        elif choice == "3":
            extract_interview_experience()
        elif choice == "4":
            interview_assistant_mode()
        elif choice == "5":
            view_json_reports()
        elif choice == "6":
            print_message("å†è§ï¼")
        else:
            print_message("æ— æ•ˆé€‰æ‹©ï¼Œé€€å‡ºç¨‹åº")

    except KeyboardInterrupt:
        print_message("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print_message(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print_message("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print_message(traceback.format_exc())


if __name__ == "__main__":
    main()
