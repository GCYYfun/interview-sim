import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from menglong import Model
from menglong.ml_model.schema.ml_request import UserMessage as user
from typing import Dict, List, Optional
import glob


class InterviewAssistant:
    """é¢è¯•è¾…åŠ©è¿½é—®Agent - åŸºäºç®€å†å’ŒJDç”Ÿæˆé’ˆå¯¹æ€§çš„é¢è¯•é—®é¢˜"""

    def __init__(self):
        self.model = Model()
        self.experiences = {}
        self.load_latest_experience()

    def load_latest_experience(self):
        """åŠ è½½æœ€æ–°çš„é¢è¯•ç»éªŒ"""
        try:
            # ä¼˜å…ˆæŸ¥æ‰¾æ–°çš„é€šç”¨é¢è¯•æé—®ç»éªŒæ–‡ä»¶
            pattern = "general_interview_guidelines_*.json"
            experience_files = glob.glob(pattern)

            # å¦‚æœæ²¡æœ‰æ–°æ ¼å¼æ–‡ä»¶ï¼ŒæŸ¥æ‰¾æ—§æ ¼å¼æ–‡ä»¶
            if not experience_files:
                pattern = "interview_experience_report_*.json"
                experience_files = glob.glob(pattern)

            if experience_files:
                latest_file = max(
                    experience_files, key=lambda x: Path(x).stat().st_mtime
                )
                with open(latest_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.experiences["integrated"] = data.get(
                        "integrated_experience", ""
                    )
                print(f"âœ… å·²åŠ è½½ç»éªŒåº“: {latest_file}")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°ç»éªŒæŠ¥å‘Šï¼Œå°†ä½¿ç”¨åŸºç¡€é¢è¯•æŠ€å·§")
                self.experiences["integrated"] = self._get_default_experience()
        except Exception as e:
            print(f"âŒ åŠ è½½ç»éªŒå¤±è´¥: {str(e)}")
            self.experiences["integrated"] = self._get_default_experience()

    def _get_default_experience(self) -> str:
        """è·å–é»˜è®¤çš„é¢è¯•ç»éªŒ"""
        return """
# åŸºç¡€é¢è¯•æŠ€å·§

## èªæ˜åº¦è¯„ä¼°
- é€šè¿‡å…·ä½“åœºæ™¯æµ‹è¯•é€»è¾‘æ€ç»´
- é€’è¿›å¼è¿½é—®éªŒè¯å­¦ä¹ èƒ½åŠ›
- è§‚å¯Ÿä¸¾ä¸€åä¸‰çš„èƒ½åŠ›

## çš®å®è¯„ä¼°
- æŒ–æ˜æŒ«æŠ˜ç»å†å’Œåº”å¯¹æ–¹å¼
- é€‚åº¦å‹åŠ›æµ‹è¯•
- è§‚å¯Ÿæƒ…ç»ªç¨³å®šæ€§

## å‹¤å¥‹è¯„ä¼°
- éªŒè¯å…·ä½“è¡Œä¸ºå’Œæ—¶é—´æŠ•å…¥
- åŒºåˆ†ä¸»åŠ¨æ€§å’Œè¢«åŠ¨å®Œæˆ
- è€ƒå¯ŸæŒç»­æ€§è¡¨ç°
"""

    def _extract_token_usage(self, response) -> Dict:
        """ä»å“åº”ä¸­æå–tokenä½¿ç”¨æƒ…å†µ"""
        try:
            if hasattr(response, "usage"):
                usage = response.usage
                return {
                    "input_tokens": getattr(usage, "input_tokens", 0),
                    "output_tokens": getattr(usage, "output_tokens", 0),
                    "total_tokens": getattr(usage, "total_tokens", 0),
                }
            else:
                return {
                    "input_tokens": 0,
                    "output_tokens": 0,
                    "total_tokens": 0,
                }
        except Exception as e:
            print(f"âš ï¸ æå–tokenä½¿ç”¨æƒ…å†µæ—¶å‡ºé”™: {str(e)}")
            return {
                "input_tokens": 0,
                "output_tokens": 0,
                "total_tokens": 0,
            }

    def _extract_response_text(self, response) -> str:
        """ä»LLMå“åº”ä¸­æå–æ–‡æœ¬å†…å®¹"""
        try:
            if hasattr(response, "message") and hasattr(response.message, "content"):
                if hasattr(response.message.content, "text"):
                    return response.message.content.text
                else:
                    return str(response.message.content)
            elif hasattr(response, "content"):
                return str(response.content)
            else:
                return str(response)
        except Exception as e:
            print(f"âš ï¸ æå–å“åº”æ–‡æœ¬æ—¶å‡ºé”™: {str(e)}")
            return str(response)

    def generate_interview_questions(
        self, resume: str, jd: str, focus_areas: List[str] = None
    ) -> Dict:
        """
        æ ¹æ®ç®€å†å’ŒJDç”Ÿæˆé’ˆå¯¹æ€§çš„é¢è¯•é—®é¢˜

        Args:
            resume: å€™é€‰äººç®€å†
            jd: å²—ä½æè¿°
            focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸï¼Œå¦‚['èªæ˜åº¦', 'çš®å®', 'å‹¤å¥‹']

        Returns:
            åŒ…å«é—®é¢˜å’Œè¿½é—®ç­–ç•¥çš„å­—å…¸
        """
        if focus_areas is None:
            focus_areas = ["èªæ˜åº¦", "çš®å®", "å‹¤å¥‹"]

        focus_str = "ã€".join(focus_areas)

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„HRé¢è¯•ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ä¸ºå³å°†åˆ°æ¥çš„é¢è¯•ç”Ÿæˆé’ˆå¯¹æ€§çš„é—®é¢˜å’Œè¿½é—®ç­–ç•¥ã€‚

## å€™é€‰äººç®€å†ï¼š
{resume}

## å²—ä½æè¿°ï¼š
{jd}

## é‡ç‚¹è¯„ä¼°ç»´åº¦ï¼š
{focus_str}

## å‚è€ƒé¢è¯•ç»éªŒåº“ï¼š
{self.experiences.get('integrated', '')}

## ä»»åŠ¡è¦æ±‚ï¼š
è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ï¼Œä¸ºè¿™ä½å€™é€‰äººè®¾è®¡ä¸€å¥—å®Œæ•´çš„é¢è¯•é—®é¢˜æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

### 1. å€™é€‰äººåˆ†æ
- ç®€å†äº®ç‚¹åˆ†æ
- æ½œåœ¨é£é™©ç‚¹è¯†åˆ«
- ä¸å²—ä½çš„åŒ¹é…åº¦è¯„ä¼°

### 2. å¼€åœºç ´å†°é—®é¢˜ï¼ˆ2-3ä¸ªï¼‰
- è®©å€™é€‰äººæ”¾æ¾çš„å¼€åœºé—®é¢˜
- åŸºäºç®€å†çš„æ¸©å’Œè¯¢é—®

### 3. æ ¸å¿ƒèƒ½åŠ›æµ‹è¯•é—®é¢˜
é’ˆå¯¹{focus_str}ï¼Œè®¾è®¡å…·ä½“çš„æµ‹è¯•é—®é¢˜ï¼š

#### èªæ˜åº¦æµ‹è¯•é—®é¢˜
- åŸºäºå²—ä½è¦æ±‚çš„åœºæ™¯å‡è®¾é¢˜
- é€»è¾‘æ€ç»´æµ‹è¯•é—®é¢˜
- å­¦ä¹ èƒ½åŠ›éªŒè¯é—®é¢˜

#### çš®å®æµ‹è¯•é—®é¢˜  
- é’ˆå¯¹ç®€å†ä¸­å¯èƒ½çš„æŒ«æŠ˜ç‚¹çš„æ·±åº¦æŒ–æ˜
- å‹åŠ›æµ‹è¯•é—®é¢˜
- æŠ—å‹èƒ½åŠ›éªŒè¯

#### å‹¤å¥‹æµ‹è¯•é—®é¢˜
- åŸºäºç®€å†ç»å†çš„å…·ä½“è¡Œä¸ºéªŒè¯
- ä¸»åŠ¨æ€§å’ŒæŒç»­æ€§è€ƒå¯Ÿ
- æ—¶é—´æŠ•å…¥å’ŒæˆæœéªŒè¯

### 4. æ·±åº¦è¿½é—®ç­–ç•¥
å¯¹äºæ¯ä¸ªæ ¸å¿ƒé—®é¢˜ï¼Œæä¾›ï¼š
- å¦‚æœå€™é€‰äººå›ç­”ä¼˜ç§€ï¼Œå¦‚ä½•è¿›ä¸€æ­¥éªŒè¯
- å¦‚æœå€™é€‰äººå›ç­”ä¸€èˆ¬ï¼Œå¦‚ä½•æ·±åº¦æŒ–æ˜
- å¦‚æœå€™é€‰äººå›é¿é—®é¢˜ï¼Œå¦‚ä½•å·§å¦™è¿½é—®

### 5. é£é™©é¢„è­¦
- éœ€è¦ç‰¹åˆ«å…³æ³¨çš„å›ç­”æ¨¡å¼
- å¯èƒ½çš„å¤¸å¤§æˆ–è™šå‡ä¿¡æ¯è¯†åˆ«ç‚¹
- ä¸åŒ¹é…çš„å±é™©ä¿¡å·

### 6. ç»“å°¾é—®é¢˜ï¼ˆ1-2ä¸ªï¼‰
- äº†è§£å€™é€‰äººæœŸæœ›å’ŒåŠ¨æœº
- ç»™å€™é€‰äººæé—®çš„æœºä¼š

## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- ç»“æ„æ¸…æ™°ï¼Œä¾¿äºé¢è¯•å®˜å¿«é€ŸæŸ¥é˜…
- æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰æ˜ç¡®çš„è¯„ä¼°ç›®çš„
- æä¾›å…·ä½“çš„è§‚å¯Ÿè¦ç‚¹å’Œè¯„åˆ†æ ‡å‡†
- ç»™å‡ºé¢„æœŸçš„ä¼˜ç§€å›ç­”ç¤ºä¾‹

è¯·ç¡®ä¿é—®é¢˜è®¾è®¡å…·æœ‰é’ˆå¯¹æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å€™é€‰äººçš„çœŸå®èƒ½åŠ›æ°´å¹³ã€‚"""

        try:
            print("ğŸ¤– æ­£åœ¨æ ¹æ®ç®€å†å’ŒJDç”Ÿæˆé¢è¯•é—®é¢˜...")
            response = self.model.chat([user(content=prompt)])
            questions_text = self._extract_response_text(response)

            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "candidate_resume": (
                    resume[:200] + "..." if len(resume) > 200 else resume
                ),
                "job_description": jd[:200] + "..." if len(jd) > 200 else jd,
                "focus_areas": focus_areas,
                "generated_questions": questions_text,
                "generation_time": datetime.now().isoformat(),
                "token_usage": self._extract_token_usage(response),
            }

            print("âœ… é¢è¯•é—®é¢˜ç”Ÿæˆå®Œæˆ!")
            return result

        except Exception as e:
            print(f"âŒ ç”Ÿæˆé¢è¯•é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
            return {"error": str(e)}

    def analyze_candidate_fit(self, resume: str, jd: str) -> Dict:
        """
        åˆ†æå€™é€‰äººä¸å²—ä½çš„åŒ¹é…åº¦

        Args:
            resume: å€™é€‰äººç®€å†
            jd: å²—ä½æè¿°

        Returns:
            åŒ¹é…åº¦åˆ†æç»“æœ
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„HRä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹å€™é€‰äººä¸å²—ä½çš„åŒ¹é…æƒ…å†µã€‚

## å€™é€‰äººç®€å†ï¼š
{resume}

## å²—ä½æè¿°ï¼š
{jd}

## åˆ†æè¦æ±‚ï¼š
è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œè¯¦ç»†åˆ†æï¼š

### 1. ç¡¬æŠ€èƒ½åŒ¹é…åº¦ï¼ˆ1-10åˆ†ï¼‰
- æŠ€æœ¯èƒ½åŠ›åŒ¹é…æƒ…å†µ
- è¡Œä¸šç»éªŒç›¸å…³æ€§
- å­¦å†èƒŒæ™¯é€‚é…æ€§

### 2. è½¯æŠ€èƒ½åŒ¹é…åº¦ï¼ˆ1-10åˆ†ï¼‰
- æ²Ÿé€šåè°ƒèƒ½åŠ›
- å›¢é˜Ÿåˆä½œç²¾ç¥
- æŠ—å‹å’Œé€‚åº”èƒ½åŠ›

### 3. ç»éªŒåŒ¹é…åº¦ï¼ˆ1-10åˆ†ï¼‰
- ç›¸å…³å·¥ä½œç»éªŒ
- é¡¹ç›®ç»éªŒåŒ¹é…
- æˆé•¿è½¨è¿¹åˆç†æ€§

### 4. æ–‡åŒ–åŒ¹é…åº¦ï¼ˆ1-10åˆ†ï¼‰
- ä»·å€¼è§‚åŒ¹é…
- å·¥ä½œé£æ ¼é€‚é…
- å‘å±•æ„æ„¿å¥‘åˆåº¦

### 5. ç»¼åˆè¯„ä¼°
- æ€»ä½“åŒ¹é…åº¦è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
- ä¸»è¦ä¼˜åŠ¿ï¼ˆTOP 3ï¼‰
- ä¸»è¦é£é™©ç‚¹ï¼ˆTOP 3ï¼‰
- é¢è¯•é‡ç‚¹å…³æ³¨äº‹é¡¹

### 6. é¢è¯•å»ºè®®
- éœ€è¦é‡ç‚¹éªŒè¯çš„èƒ½åŠ›
- å¯èƒ½çš„åŠ åˆ†é¡¹æŒ–æ˜
- é£é™©ç‚¹æ¢æŸ¥ç­–ç•¥

è¯·æä¾›å…·ä½“çš„è¯„åˆ†ç†ç”±å’Œå»ºè®®ã€‚"""

        try:
            print("ğŸ” æ­£åœ¨åˆ†æå€™é€‰äººåŒ¹é…åº¦...")
            response = self.model.chat([user(content=prompt)])
            analysis_text = self._extract_response_text(response)

            result = {
                "candidate_resume": (
                    resume[:200] + "..." if len(resume) > 200 else resume
                ),
                "job_description": jd[:200] + "..." if len(jd) > 200 else jd,
                "fit_analysis": analysis_text,
                "analysis_time": datetime.now().isoformat(),
                "token_usage": self._extract_token_usage(response),
            }

            print("âœ… åŒ¹é…åº¦åˆ†æå®Œæˆ!")
            return result

        except Exception as e:
            print(f"âŒ åˆ†æåŒ¹é…åº¦æ—¶å‡ºé”™: {str(e)}")
            return {"error": str(e)}

    def save_interview_plan(
        self, questions_result: Dict, output_path: str = None, candidate_id: str = None
    ) -> str:
        """ä¿å­˜é¢è¯•æ–¹æ¡ˆåˆ°æ–‡ä»¶"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            if candidate_id:
                output_path = f"interview_plan_{candidate_id}_{timestamp}.json"
            else:
                output_path = f"interview_plan_candidate_{timestamp}.json"

        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(questions_result, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“‹ é¢è¯•æ–¹æ¡ˆå·²ä¿å­˜åˆ°: {output_path}")
            return output_path

        except Exception as e:
            print(f"âŒ ä¿å­˜é¢è¯•æ–¹æ¡ˆå¤±è´¥: {str(e)}")
            return ""

    def load_candidate_data(
        self, csv_file: str = "interview_data.csv", record_id: int = 0
    ) -> Dict:
        """
        ä»CSVæ–‡ä»¶åŠ è½½å€™é€‰äººæ•°æ®

        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„
            record_id: è®°å½•ID

        Returns:
            åŒ…å«ç®€å†å’ŒJDçš„å­—å…¸
        """
        try:
            df = pd.read_csv(csv_file)
            if record_id >= len(df):
                raise ValueError(
                    f"è®°å½•ID {record_id} è¶…å‡ºèŒƒå›´ï¼Œæ•°æ®å…±æœ‰ {len(df)} æ¡è®°å½•"
                )

            row = df.iloc[record_id]
            return {
                "resume": row.get("å€™é€‰äººè„±æ•ç®€å†", ""),
                "jd": row.get("å²—ä½è„±æ•jd", ""),
                "position": row.get("å²—ä½åç§°", ""),
                "required_intelligence": row.get("è¯¥å²—ä½è¦æ±‚çš„èªæ˜åº¦ï¼ˆæ»¡åˆ†ååˆ†ï¼‰", 0),
            }

        except Exception as e:
            print(f"âŒ åŠ è½½å€™é€‰äººæ•°æ®å¤±è´¥: {str(e)}")
            return {}
